{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyper",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UtrCvbS4RG7"
      },
      "source": [
        "from __future__ import annotations\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP7lLgUQ5nii",
        "outputId": "54f418b1-f5eb-4cf0-cbd6-ba9dec43d08d"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0tYmkTi4Tj-",
        "outputId": "e6a17d30-dfb8-4929-9c4d-5abc839a9304"
      },
      "source": [
        "!pip install mxnet-cu101\n",
        "\n",
        "from typing import Tuple, Union\n",
        "from mxnet import nd, symbol\n",
        "from mxnet.gluon.nn import HybridBlock\n",
        "from mxnet.gluon.parameter import Parameter\n",
        "from mxnet.initializer import Zero\n",
        "from mxnet.gluon.nn import Conv2D, HybridSequential, LeakyReLU, Dense\n",
        "from mxnet import nd, gluon, autograd\n",
        "import mxnet as mx\n",
        "from mxnet.io import NDArrayIter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu101 in /usr/local/lib/python3.7/dist-packages (1.7.0.post1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP1X8zSQ4Tmh"
      },
      "source": [
        "def load_dataset(t, x, batch_size):\n",
        "    return NDArrayIter({ \"x\": nd.stack(*x, axis=0) }, { \"t\": nd.stack(*t, axis=0) }, batch_size, True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBAbcsjq4To6"
      },
      "source": [
        "class Linear(HybridSequential):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(Linear, self).__init__()\n",
        "        with self.name_scope():\n",
        "            self.add(Dense(n_out, in_units=n_in))\n",
        "\n",
        "\n",
        "class Pixelnorm(HybridBlock):\n",
        "    def __init__(self, epsilon: float = 1e-8) -> None:\n",
        "        super(Pixelnorm, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def hybrid_forward(self, F, x) -> nd:\n",
        "        return x * F.rsqrt(F.mean(F.square(x), 1, True) + self.epsilon)\n",
        "\n",
        "\n",
        "class Bias(HybridBlock):\n",
        "    def __init__(self, shape: Tuple) -> None:\n",
        "        super(Bias, self).__init__()\n",
        "        self.shape = shape\n",
        "        with self.name_scope():\n",
        "            self.b = self.params.get(\"b\", init=Zero(), shape=shape)\n",
        "\n",
        "    def hybrid_forward(self, F, x, b) -> nd:\n",
        "        return F.broadcast_add(x, b[None, :, None, None])\n",
        "\n",
        "\n",
        "class Block(HybridSequential):\n",
        "    def __init__(self, channels: int, in_channels: int) -> None:\n",
        "        super(Block, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.in_channels = in_channels\n",
        "        with self.name_scope():\n",
        "            self.add(Conv2D(channels, 3, padding=1, in_channels=in_channels))\n",
        "            self.add(LeakyReLU(0.2))\n",
        "            self.add(Pixelnorm())\n",
        "            self.add(Conv2D(channels, 3, padding=1, in_channels=channels))\n",
        "            self.add(LeakyReLU(0.2))\n",
        "            self.add(Pixelnorm())\n",
        "\n",
        "    def hybrid_forward(self, F, x) -> nd:\n",
        "        x = F.repeat(x, 2, 2)\n",
        "        x = F.repeat(x, 2, 3)\n",
        "        for i in range(len(self)):\n",
        "            x = self[i](x)\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbt6GO9Y4Trm"
      },
      "source": [
        "class Generator(HybridSequential):\n",
        "    def __init__(self) -> None:\n",
        "        super(Generator, self).__init__()\n",
        "        with self.name_scope():\n",
        "            self.add(Pixelnorm())\n",
        "            self.add(Dense(8192, use_bias=False, in_units=512))\n",
        "            self.add(Bias((512,)))\n",
        "            self.add(LeakyReLU(0.2))\n",
        "            self.add(Pixelnorm())\n",
        "            self.add(Conv2D(512, 3, padding=1, in_channels=512))\n",
        "            self.add(LeakyReLU(0.2))\n",
        "            self.add(Pixelnorm())\n",
        "            \n",
        "            self.add(Block(512, 512)) # 8\n",
        "            self.add(Block(512, 512))\n",
        "            self.add(Block(512, 512))\n",
        "            self.add(Block(256, 512))\n",
        "            self.add(Block(128, 256))\n",
        "            self.add(Block(64, 128))\n",
        "            self.add(Block(32, 64))\n",
        "            self.add(Block(16, 32)) # 15\n",
        "            self.add(Conv2D(3, 1, in_channels=16))\n",
        "\n",
        "\n",
        "    def hybrid_forward(self, F: Union(nd, symbol), x: nd, layer: int) -> nd:\n",
        "        x = F.Reshape(self[1](self[0](x)), (-1, 512, 4, 4))\n",
        "        for i in range(2, len(self)):\n",
        "            x = self[i](x)\n",
        "            if i == layer + 7:\n",
        "              return x\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URXm1Nk54fz3"
      },
      "source": [
        "max_epoch = 1500\n",
        "batch_size = 30\n",
        "n_vox = 4096\n",
        "n_lat = 512"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD8Fux7h4f2U"
      },
      "source": [
        "# Note that we are using gradient descent to fit the weights of the dense layer whereas ordinary least squares would yield a similar\n", 
        "# solution. However, the current setup allows you to experiment and try different things to make more sophisticated models (e.g., predict\n", 
        "intermediate layer activations of PGGAN and include this in your loss function).",
        "generator = Generator()\n",
        "generator.load_parameters(\"/content/drive/MyDrive/HYPER/data/generator.params\")\n",
        "mean_squared_error = gluon.loss.L2Loss()\n",
        "for subject in [1, 2]:\n",
        "      \n",
        "      # Data\n",
        "      with open(\"/content/drive/MyDrive/HYPER/data/data_%i.dat\" % subject, 'rb') as f:\n",
        "          X_tr, T_tr, X_te, T_te = pickle.load(f)\n",
        "      train = load_dataset(nd.array(T_tr), nd.array(X_tr), batch_size)        \n",
        "      test =  load_dataset(nd.array(T_te), nd.array(X_te), batch_size=36)  \n",
        "\n",
        "      # Training\n",
        "      vox_to_lat = Linear(n_vox, n_lat)\n",
        "      vox_to_lat.initialize()\n",
        "      trainer = gluon.Trainer(vox_to_lat.collect_params(), \"Adam\", {\"learning_rate\": 0.00001, \"wd\": 0.01})\n",
        "      epoch = 0\n",
        "      results_tr = []\n",
        "      results_te = []\n",
        "      while epoch < max_epoch:\n",
        "          train.reset()\n",
        "          test.reset()\n",
        "          loss_tr = 0\n",
        "          loss_te = 0\n",
        "          count = 0\n",
        "          for batch_tr in train:\n",
        "              with autograd.record():\n",
        "                  lat_Y = vox_to_lat(batch_tr.data[0])\n",
        "                  loss = mean_squared_error(lat_Y, batch_tr.label[0])\n",
        "              loss.backward()\n",
        "              trainer.step(batch_size)\n",
        "              loss_tr += loss.mean().asnumpy()\n",
        "              count += 1\n",
        "          for batch_te in test:\n",
        "              lat_Y = vox_to_lat(batch_te.data[0])\n",
        "              loss = mean_squared_error(lat_Y, batch_te.label[0])\n",
        "              loss_te += loss.mean().asnumpy()\n",
        "          loss_tr_normalized = loss_tr / count\n",
        "          results_tr.append(loss_tr_normalized)\n",
        "          results_te.append(loss_te)\n",
        "          epoch += 1\n",
        "          print(\"Epoch %i: %.4f / %.4f\" % (epoch, loss_tr_normalized, loss_te))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.plot(np.linspace(0, epoch, epoch), results_tr)\n",
        "      plt.plot(np.linspace(0, epoch, epoch), results_te)\n",
        "      plt.savefig(\"loss_s%i.png\" % subject)\n",
        "\n",
        "      # Testing and reconstructing\n",
        "      lat_Y = vox_to_lat(nd.array(X_te))\n",
        "      dir = '/content/faces_%i' % subject\n",
        "      if not os.path.exists(dir):\n",
        "          os.mkdir(dir)\n",
        "      for i, latent in enumerate(lat_Y):\n",
        "          face = generator(latent[None], 9).asnumpy()\n",
        "          face = np.clip(np.rint(127.5 * face + 127.5), 0.0, 255.0)\n",
        "          face = face.astype(\"uint8\")\n",
        "          face = face.transpose(0, 2, 3, 1)\n",
        "          Image.fromarray(face[0], 'RGB').save(dir + \"/%d.png\" % i)"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}
